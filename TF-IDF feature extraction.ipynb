{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3da9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e38fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "editorial = \"Samples are comprised of one or more variables generally easy to devise or create. One sample is often defined as a vector of variables with a predefined range in an n-dimensional space. This space must be sampled and explored in order to find the specific combination of variable values that result in the best cost.The cost often has units that are specific to a given domain. Optimization is often described in terms of minimizing cost, as a maximization problem can easily be transformed into a minimization problem by inverting the calculated cost. Together, the minimum and maximum of a function are referred to as the extreme of the function (or the plural extrema).The objective function is often easy to specify but can be computationally challenging to calculate or result in a noisy calculation of cost over time. The form of the objective function is unknown and is often highly nonlinear, and highly multi-dimensional defined by the number of input variables. The function is also probably non-convex. This means that local extrema may or may not be the global extrema (e.g. could be misleading and result in premature convergence), hence the name of the task as global rather than local optimization.Although little is known about the objective function, (it is known whether the minimum or the maximum cost from the function is sought), and as such, it is often referred to as a black box function and the search process as black box optimization. Further, the objective function is sometimes called an oracle given the ability to only give answers.Function optimization is a fundamental part of machine learning. Most machine learning algorithms involve the optimization of parameters (weights, coefficients, etc.) in response to training data. Optimization also refers to the process of finding the best set of hyperparameters that configure the training of a machine learning algorithm. Taking one step higher again, the selection of training data, data preparation, and machine learning algorithms themselves is also a problem of function optimization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8d1502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Samples are comprised of one or more variables generally easy to devise or create. One sample is often defined as a vector of variables with a predefined range in an n-dimensional space. This space must be sampled and explored in order to find the specific combination of variable values that result in the best cost.The cost often has units that are specific to a given domain. Optimization is often described in terms of minimizing cost, as a maximization problem can easily be transformed into a minimization problem by inverting the calculated cost. Together, the minimum and maximum of a function are referred to as the extreme of the function (or the plural extrema).The objective function is often easy to specify but can be computationally challenging to calculate or result in a noisy calculation of cost over time. The form of the objective function is unknown and is often highly nonlinear, and highly multi-dimensional defined by the number of input variables. The function is also probably non-convex. This means that local extrema may or may not be the global extrema (e.g. could be misleading and result in premature convergence), hence the name of the task as global rather than local optimization.Although little is known about the objective function, (it is known whether the minimum or the maximum cost from the function is sought), and as such, it is often referred to as a black box function and the search process as black box optimization. Further, the objective function is sometimes called an oracle given the ability to only give answers.Function optimization is a fundamental part of machine learning. Most machine learning algorithms involve the optimization of parameters (weights, coefficients, etc.) in response to training data. Optimization also refers to the process of finding the best set of hyperparameters that configure the training of a machine learning algorithm. Taking one step higher again, the selection of training data, data preparation, and machine learning algorithms themselves is also a problem of function optimization'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a64b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemm = WordNetLemmatizer()\n",
    "\n",
    "sentence = nltk.sent_tokenize(editorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12caced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Samples are comprised of one or more variables generally easy to devise or create.',\n",
       " 'One sample is often defined as a vector of variables with a predefined range in an n-dimensional space.',\n",
       " 'This space must be sampled and explored in order to find the specific combination of variable values that result in the best cost.The cost often has units that are specific to a given domain.',\n",
       " 'Optimization is often described in terms of minimizing cost, as a maximization problem can easily be transformed into a minimization problem by inverting the calculated cost.',\n",
       " 'Together, the minimum and maximum of a function are referred to as the extreme of the function (or the plural extrema).The objective function is often easy to specify but can be computationally challenging to calculate or result in a noisy calculation of cost over time.',\n",
       " 'The form of the objective function is unknown and is often highly nonlinear, and highly multi-dimensional defined by the number of input variables.',\n",
       " 'The function is also probably non-convex.',\n",
       " 'This means that local extrema may or may not be the global extrema (e.g.',\n",
       " 'could be misleading and result in premature convergence), hence the name of the task as global rather than local optimization.Although little is known about the objective function, (it is known whether the minimum or the maximum cost from the function is sought), and as such, it is often referred to as a black box function and the search process as black box optimization.',\n",
       " 'Further, the objective function is sometimes called an oracle given the ability to only give answers.Function optimization is a fundamental part of machine learning.',\n",
       " 'Most machine learning algorithms involve the optimization of parameters (weights, coefficients, etc.)',\n",
       " 'in response to training data.',\n",
       " 'Optimization also refers to the process of finding the best set of hyperparameters that configure the training of a machine learning algorithm.',\n",
       " 'Taking one step higher again, the selection of training data, data preparation, and machine learning algorithms themselves is also a problem of function optimization']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34267aa",
   "metadata": {},
   "source": [
    "Clean the text before applying extraction method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db20c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    words = re.sub('[^a-zA-Z]',' ',sentence[i])\n",
    "    words = words.lower()\n",
    "    words = words.split()\n",
    "    words = [lemm.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    words = ' '.join(words)\n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09118c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample comprised one variable generally easy devise create',\n",
       " 'one sample often defined vector variable predefined range n dimensional space',\n",
       " 'space must sampled explored order find specific combination variable value result best cost cost often unit specific given domain',\n",
       " 'optimization often described term minimizing cost maximization problem easily transformed minimization problem inverting calculated cost',\n",
       " 'together minimum maximum function referred extreme function plural extremum objective function often easy specify computationally challenging calculate result noisy calculation cost time',\n",
       " 'form objective function unknown often highly nonlinear highly multi dimensional defined number input variable',\n",
       " 'function also probably non convex',\n",
       " 'mean local extremum may may global extremum e g',\n",
       " 'could misleading result premature convergence hence name task global rather local optimization although little known objective function known whether minimum maximum cost function sought often referred black box function search process black box optimization',\n",
       " 'objective function sometimes called oracle given ability give answer function optimization fundamental part machine learning',\n",
       " 'machine learning algorithm involve optimization parameter weight coefficient etc',\n",
       " 'response training data',\n",
       " 'optimization also refers process finding best set hyperparameters configure training machine learning algorithm',\n",
       " 'taking one step higher selection training data data preparation machine learning algorithm also problem function optimization']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91095056",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a962abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e36345",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(corpus).toarray()\n",
    "df = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "300cb355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.36722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200661</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231841</td>\n",
       "      <td>0.161380</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191950</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388231</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.33408</td>\n",
       "      <td>0.33408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.16704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.289755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.289755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.380591</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279518</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2        3         4         5        6    \\\n",
       "0   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "1   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "2   0.000000  0.000000  0.000000  0.00000  0.000000  0.200661  0.00000   \n",
       "3   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "4   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "5   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "6   0.000000  0.000000  0.388231  0.00000  0.000000  0.000000  0.00000   \n",
       "7   0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "8   0.000000  0.000000  0.000000  0.16704  0.000000  0.000000  0.33408   \n",
       "9   0.289755  0.000000  0.000000  0.00000  0.289755  0.000000  0.00000   \n",
       "10  0.000000  0.293091  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "11  0.000000  0.000000  0.000000  0.00000  0.000000  0.000000  0.00000   \n",
       "12  0.000000  0.248702  0.248702  0.00000  0.000000  0.279518  0.00000   \n",
       "13  0.000000  0.215500  0.215500  0.00000  0.000000  0.000000  0.00000   \n",
       "\n",
       "        7         8         9    ...       107       108       109       110  \\\n",
       "0   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "1   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.231841   \n",
       "3   0.00000  0.000000  0.261553  ...  0.000000  0.000000  0.261553  0.000000   \n",
       "4   0.00000  0.231102  0.000000  ...  0.231102  0.000000  0.000000  0.000000   \n",
       "5   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "7   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "8   0.33408  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "9   0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "10  0.00000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "11  0.00000  0.000000  0.000000  ...  0.000000  0.503194  0.000000  0.000000   \n",
       "12  0.00000  0.000000  0.000000  ...  0.000000  0.248702  0.000000  0.000000   \n",
       "13  0.00000  0.000000  0.000000  ...  0.000000  0.215500  0.000000  0.000000   \n",
       "\n",
       "         111       112       113      114       115      116  \n",
       "0   0.000000  0.000000  0.271447  0.00000  0.000000  0.00000  \n",
       "1   0.000000  0.000000  0.255614  0.36722  0.000000  0.00000  \n",
       "2   0.000000  0.231841  0.161380  0.00000  0.000000  0.00000  \n",
       "3   0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "4   0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "5   0.275758  0.000000  0.191950  0.00000  0.000000  0.00000  \n",
       "6   0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "7   0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "8   0.000000  0.000000  0.000000  0.00000  0.000000  0.16704  \n",
       "9   0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "10  0.000000  0.000000  0.000000  0.00000  0.380591  0.00000  \n",
       "11  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "12  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "13  0.000000  0.000000  0.000000  0.00000  0.000000  0.00000  \n",
       "\n",
       "[14 rows x 117 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75c2a0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': 92,\n",
       " 'comprised': 15,\n",
       " 'one': 73,\n",
       " 'variable': 113,\n",
       " 'generally': 40,\n",
       " 'easy': 30,\n",
       " 'devise': 26,\n",
       " 'create': 22,\n",
       " 'often': 72,\n",
       " 'defined': 24,\n",
       " 'vector': 114,\n",
       " 'predefined': 80,\n",
       " 'range': 86,\n",
       " 'dimensional': 27,\n",
       " 'space': 99,\n",
       " 'must': 65,\n",
       " 'sampled': 93,\n",
       " 'explored': 32,\n",
       " 'order': 76,\n",
       " 'find': 35,\n",
       " 'specific': 100,\n",
       " 'combination': 14,\n",
       " 'value': 112,\n",
       " 'result': 91,\n",
       " 'best': 5,\n",
       " 'cost': 20,\n",
       " 'unit': 110,\n",
       " 'given': 42,\n",
       " 'domain': 28,\n",
       " 'optimization': 74,\n",
       " 'described': 25,\n",
       " 'term': 105,\n",
       " 'minimizing': 61,\n",
       " 'maximization': 56,\n",
       " 'problem': 84,\n",
       " 'easily': 29,\n",
       " 'transformed': 109,\n",
       " 'minimization': 60,\n",
       " 'inverting': 49,\n",
       " 'calculated': 9,\n",
       " 'together': 107,\n",
       " 'minimum': 62,\n",
       " 'maximum': 57,\n",
       " 'function': 38,\n",
       " 'referred': 88,\n",
       " 'extreme': 33,\n",
       " 'plural': 79,\n",
       " 'extremum': 34,\n",
       " 'objective': 71,\n",
       " 'specify': 101,\n",
       " 'computationally': 16,\n",
       " 'challenging': 12,\n",
       " 'calculate': 8,\n",
       " 'noisy': 67,\n",
       " 'calculation': 10,\n",
       " 'time': 106,\n",
       " 'form': 37,\n",
       " 'unknown': 111,\n",
       " 'highly': 46,\n",
       " 'nonlinear': 69,\n",
       " 'multi': 64,\n",
       " 'number': 70,\n",
       " 'input': 48,\n",
       " 'also': 2,\n",
       " 'probably': 83,\n",
       " 'non': 68,\n",
       " 'convex': 19,\n",
       " 'mean': 59,\n",
       " 'local': 54,\n",
       " 'may': 58,\n",
       " 'global': 43,\n",
       " 'could': 21,\n",
       " 'misleading': 63,\n",
       " 'premature': 81,\n",
       " 'convergence': 18,\n",
       " 'hence': 44,\n",
       " 'name': 66,\n",
       " 'task': 104,\n",
       " 'rather': 87,\n",
       " 'although': 3,\n",
       " 'little': 53,\n",
       " 'known': 51,\n",
       " 'whether': 116,\n",
       " 'sought': 98,\n",
       " 'black': 6,\n",
       " 'box': 7,\n",
       " 'search': 94,\n",
       " 'process': 85,\n",
       " 'sometimes': 97,\n",
       " 'called': 11,\n",
       " 'oracle': 75,\n",
       " 'ability': 0,\n",
       " 'give': 41,\n",
       " 'answer': 4,\n",
       " 'fundamental': 39,\n",
       " 'part': 78,\n",
       " 'machine': 55,\n",
       " 'learning': 52,\n",
       " 'algorithm': 1,\n",
       " 'involve': 50,\n",
       " 'parameter': 77,\n",
       " 'weight': 115,\n",
       " 'coefficient': 13,\n",
       " 'etc': 31,\n",
       " 'response': 90,\n",
       " 'training': 108,\n",
       " 'data': 23,\n",
       " 'refers': 89,\n",
       " 'finding': 36,\n",
       " 'set': 96,\n",
       " 'hyperparameters': 47,\n",
       " 'configure': 17,\n",
       " 'taking': 103,\n",
       " 'step': 102,\n",
       " 'higher': 45,\n",
       " 'selection': 95,\n",
       " 'preparation': 82}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0eae3",
   "metadata": {},
   "source": [
    "### Spam or Ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926c4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed981ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6a54fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>147</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>157</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...     147      8\n",
       "6   ham  Even my brother is not like to speak with me. ...      77      2\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...     160      6\n",
       "8  spam  WINNER!! As a valued network customer you have...     157      6\n",
       "9  spam  Had your mobile 11 months or more? U R entitle...     154      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e91881e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89b5a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataset shows no null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9295bb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      " 2   length   5572 non-null   int64 \n",
      " 3   punct    5572 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 174.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb24d6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572.000000</td>\n",
       "      <td>5572.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80.489950</td>\n",
       "      <td>4.177495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>59.942907</td>\n",
       "      <td>4.623919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>910.000000</td>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            length        punct\n",
       "count  5572.000000  5572.000000\n",
       "mean     80.489950     4.177495\n",
       "std      59.942907     4.623919\n",
       "min       2.000000     0.000000\n",
       "25%      36.000000     2.000000\n",
       "50%      62.000000     3.000000\n",
       "75%     122.000000     6.000000\n",
       "max     910.000000   133.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c676d881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The data is highly imbalanced and the results will be biased \n",
    "df['label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f406a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The SMOTE ,undersampling method or any other regular sampling doesnt work in Text Analytics\n",
    "# Basic Numpy samples will be used in this\n",
    "ham = df[df['label']=='ham']\n",
    "spam = df[df['label'] =='spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c55fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4825, 4) (747, 4)\n"
     ]
    }
   ],
   "source": [
    "print(ham.shape,spam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045606e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace = True is because it cannot make more sample than spam's size without replacing\n",
    "spam = spam.sample(ham.shape[0],replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba0bddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_21536\\3655962713.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = ham.append(spam,ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "data = ham.append(spam,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf37d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9650, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd0578c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>109</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2   ham  U dun say so early hor... U c already then say...      49      6\n",
       "3   ham  Nah I don't think he goes to usf, he lives aro...      61      2\n",
       "4   ham  Even my brother is not like to speak with me. ...      77      2\n",
       "5   ham  As per your request 'Melle Melle (Oru Minnamin...     160      6\n",
       "6   ham  I'm gonna be home soon and i don't want to tal...     109      6\n",
       "7   ham  I've been searching for the right words to tha...     196      4\n",
       "8   ham                I HAVE A DATE ON SUNDAY WITH WILL!!      35      2\n",
       "9   ham                         Oh k...i'm watching here:)      26      6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "186e273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['message'],df['label'],\n",
    "                                                 test_size = 0.3,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "544b540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature_ Extraction before builidng the modle(TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Build Classification model(Random Forest Classifier)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create the Pipeline to build a ML model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c40cc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = Pipeline([('tfidf',TfidfVectorizer(stop_words = stopwords.words('english'))),\n",
    "                                ('randomforest',RandomForestClassifier(n_estimators = 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57f2de4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('randomforest', RandomForestClassifier())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ed1c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train =classification_model.predict(x_train)\n",
    "y_pred_test = classification_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c5b337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1469994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3350,    0],\n",
       "       [   0,  550]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train,y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eff4df42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1475,    0],\n",
       "       [  32,  165]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa7cde6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3350\n",
      "        spam       1.00      1.00      1.00       550\n",
      "\n",
      "    accuracy                           1.00      3900\n",
      "   macro avg       1.00      1.00      1.00      3900\n",
      "weighted avg       1.00      1.00      1.00      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc71652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1475\n",
      "        spam       1.00      0.84      0.91       197\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.99      0.92      0.95      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25b89d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0\n",
      "\n",
      "\n",
      "************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9808612440191388\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy:',accuracy_score(y_train,y_pred_train))\n",
    "print('\\n')\n",
    "print('************************************************'*10)\n",
    "print('\\n')\n",
    "print('Test Accuracy:',accuracy_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9bf9cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      1.00      1.00      3350\n",
      "        spam       1.00      1.00      1.00       550\n",
      "\n",
      "    accuracy                           1.00      3900\n",
      "   macro avg       1.00      1.00      1.00      3900\n",
      "weighted avg       1.00      1.00      1.00      3900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8c1d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1475\n",
      "        spam       1.00      0.84      0.91       197\n",
      "\n",
      "    accuracy                           0.98      1672\n",
      "   macro avg       0.99      0.92      0.95      1672\n",
      "weighted avg       0.98      0.98      0.98      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70263b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = ['Hey How are you.Are you Fine']\n",
    "test2 = ['Congratulations, you have won $2 million rupees!!!!!!!!!!!.To Claim call @546223']\n",
    "test3 = [\"From healthcare and transportation to finance and retail, there are hardly any industries left where Data Science and Machine Learning haven't made a significant impact. This is also what makes it one of the highest-paid specializations in the tech industry, with salaries that are often well above the national average.To get started in these fields, apply now to our program Data Science and Machine Learning: Making Data-Driven Decisions [delivered by MIT IDSS and Great Learning] and leverage some of the best opportunities out there! Carefully crafted by MIT faculty to provide you with the skills & knowledge covering the most business-relevant technologies, such as Machine Learning, Deep Learning, NLP, Recommendation Systems, and more.With the “learn by doing” pedagogy, master 6+ tools such as Python, Numpy, Keras, TensorFlow, and much more by working on more than 50 case studies!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ba132e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham']\n",
      "['spam']\n",
      "['ham']\n"
     ]
    }
   ],
   "source": [
    "print(classification_model.predict(test1))\n",
    "print(classification_model.predict(test2))\n",
    "print(classification_model.predict(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74fec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
